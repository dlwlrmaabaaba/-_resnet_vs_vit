{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z0SypUdej-iJ"
   },
   "source": [
    "### Imporing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-04T11:10:34.012654Z",
     "iopub.status.busy": "2024-06-04T11:10:34.011894Z",
     "iopub.status.idle": "2024-06-04T11:10:34.018027Z",
     "shell.execute_reply": "2024-06-04T11:10:34.016942Z",
     "shell.execute_reply.started": "2024-06-04T11:10:34.012618Z"
    }
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import gc\n",
    "\n",
    "# # 删除所有的张量变量\n",
    "# for obj in gc.get_objects():\n",
    "#     try:\n",
    "#         if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):\n",
    "#             del obj\n",
    "#     except:\n",
    "#         pass\n",
    "\n",
    "# # 强制进行垃圾回收\n",
    "# gc.collect()\n",
    "\n",
    "# # 清理 PyTorch 的缓存\n",
    "# torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-04T11:10:34.020682Z",
     "iopub.status.busy": "2024-06-04T11:10:34.020319Z",
     "iopub.status.idle": "2024-06-04T11:10:50.819242Z",
     "shell.execute_reply": "2024-06-04T11:10:50.818051Z",
     "shell.execute_reply.started": "2024-06-04T11:10:34.020650Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ml_collections\n",
      "  Downloading ml_collections-0.1.1.tar.gz (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m864.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from ml_collections) (1.4.0)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from ml_collections) (6.0.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from ml_collections) (1.16.0)\n",
      "Collecting contextlib2 (from ml_collections)\n",
      "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
      "Building wheels for collected packages: ml_collections\n",
      "  Building wheel for ml_collections (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ml_collections: filename=ml_collections-0.1.1-py3-none-any.whl size=94507 sha256=6ed29df3befb5edfecfaa5bf28f5bbd8661058efa2acb4c943ddedec97e44877\n",
      "  Stored in directory: /root/.cache/pip/wheels/7b/89/c9/a9b87790789e94aadcfc393c283e3ecd5ab916aed0a31be8fe\n",
      "Successfully built ml_collections\n",
      "\u001b[33mWARNING: Error parsing requirements for aiohttp: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: contextlib2, ml_collections\n",
      "Successfully installed contextlib2-21.6.0 ml_collections-0.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install ml_collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-07 11:46:00.734409: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-07 11:46:00.780841: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-07 11:46:01.567857: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import cv2\n",
    "import keras.backend as K\n",
    "from keras.datasets import cifar10, cifar100\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Flatten, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import albumentations as albu\n",
    "\n",
    "from __future__ import absolute_import, division, print_function \n",
    "import ml_collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Z21XxvYdjVbk"
   },
   "outputs": [],
   "source": [
    "import os, copy, logging, math, random, time, typing, io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import ndimage\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import CrossEntropyLoss, Dropout, Softmax, Linear, Conv2d, LayerNorm\n",
    "from torch.nn.modules.utils import _pair\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import torch.distributed as dist\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader, RandomSampler, DistributedSampler, SequentialSampler\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import utils\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from matplotlib.colors import LogNorm \n",
    "\n",
    "from urllib.request import urlretrieve\n",
    "from PIL import Image\n",
    "from os.path import join as pjoin\n",
    "\n",
    "from tqdm import tqdm\n",
    "from datetime import timedelta\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QAznk3CPp5HZ"
   },
   "source": [
    "### Download Pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-06-04T11:10:52.350695Z",
     "iopub.status.busy": "2024-06-04T11:10:52.349956Z",
     "iopub.status.idle": "2024-06-04T11:11:07.980619Z",
     "shell.execute_reply": "2024-06-04T11:11:07.979274Z",
     "shell.execute_reply.started": "2024-06-04T11:10:52.350668Z"
    },
    "id": "euVCVZTXfQ3P",
    "outputId": "8113ab4c-321d-491f-bede-8b1738596a03"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-06-04 11:10:53--  https://storage.googleapis.com/vit_models/imagenet21k/ViT-B_16.npz\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.126.207, 74.125.132.207, 74.125.201.207, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.126.207|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 412815506 (394M) [application/octet-stream]\n",
      "Saving to: 'ViT-B_16.npz.1'\n",
      "\n",
      "ViT-B_16.npz.1      100%[===================>] 393.69M  32.3MB/s    in 13s     \n",
      "\n",
      "2024-06-04 11:11:07 (29.2 MB/s) - 'ViT-B_16.npz.1' saved [412815506/412815506]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://storage.googleapis.com/vit_models/imagenet21k/ViT-B_16.npz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3XPWwVnKxLAW"
   },
   "source": [
    "### Check GPU Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mi3Rm8M7xGoP",
    "outputId": "5f672e69-0f3b-4068-89dc-ac23e2cedbf1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU:  NVIDIA GeForce RTX 4090 D\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('GPU: ', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('No GPU available')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JO2357Cexfgw"
   },
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "5phne5zGxGPI"
   },
   "outputs": [],
   "source": [
    "def get_testing():\n",
    "    '''\n",
    "    Returns a minimal configuration for testing\n",
    "    '''\n",
    "    config = ml_collections.ConfigDict()\n",
    "    config.patches = ml_collections.ConfigDict({'size': (16, 16)})\n",
    "    config.hidden_size = 1\n",
    "    config.transformer = ml_collections.ConfigDict()\n",
    "    config.transformer.mlp_dim = 1\n",
    "    config.transformer.num_heads = 1\n",
    "    config.transformer.num_layers = 1\n",
    "    config.transformer.attention_dropout_rate = 0.0\n",
    "    config.transformer.dropout_rate = 0.1\n",
    "    config.classifier = 'token'\n",
    "    config.representation_size = None\n",
    "    return config\n",
    "\n",
    "def get_b16_config():\n",
    "    '''\n",
    "    Returns the ViT-B/16 configuration\n",
    "    '''\n",
    "    config = ml_collections.ConfigDict()\n",
    "    config.patches = ml_collections.ConfigDict({'size': (16, 16)})\n",
    "    config.hidden_size = 768\n",
    "    config.transformer = ml_collections.ConfigDict()\n",
    "    config.transformer.mlp_dim = 3072\n",
    "    config.transformer.num_heads = 12\n",
    "    config.transformer.num_layers = 12\n",
    "    config.transformer.attention_dropout_rate = 0.0\n",
    "    config.transformer.dropout_rate = 0.1\n",
    "    config.classifier = 'token'\n",
    "    config.representation_size = None\n",
    "    return config\n",
    "\n",
    "def get_b32_config():\n",
    "    '''\n",
    "    Returns the ViT-B/32 configuration\n",
    "    '''\n",
    "    config = get_b16_config()\n",
    "    config.patches.size = (32, 32)\n",
    "    return config\n",
    "\n",
    "def get_l16_config():\n",
    "    '''\n",
    "    Returns the ViT-L/16 configuration\n",
    "    '''\n",
    "    config = ml_collections.ConfigDict()\n",
    "    config.patches = ml_collections.ConfigDict({'size': (16, 16)})\n",
    "    config.hidden_size = 1024\n",
    "    config.transformer = ml_collections.ConfigDict()\n",
    "    config.transformer.mlp_dim = 4096\n",
    "    config.transformer.num_heads = 16\n",
    "    config.transformer.num_layers = 24\n",
    "    config.transformer.attention_dropout_rate = 0.0\n",
    "    config.transformer.dropout_rate = 0.1\n",
    "    config.classifier = 'token'\n",
    "    config.representation_size = None\n",
    "    return config\n",
    "\n",
    "def get_l32_config():\n",
    "    '''\n",
    "    Returns the ViT-L/32 configuration\n",
    "    '''\n",
    "    config = get_l16_config()\n",
    "    config.patches.size = (32, 32)\n",
    "    return config\n",
    "\n",
    "def get_h14_config():\n",
    "    '''\n",
    "    Returns the ViT-L/16 configuration\n",
    "    '''\n",
    "    config = ml_collections.ConfigDict()\n",
    "    config.patches = ml_collections.ConfigDict({'size': (14, 14)})\n",
    "    config.hidden_size = 1280\n",
    "    config.transformer = ml_collections.ConfigDict()\n",
    "    config.transformer.mlp_dim = 5120\n",
    "    config.transformer.num_heads = 16\n",
    "    config.transformer.num_layers = 32\n",
    "    config.transformer.attention_dropout_rate = 0.0\n",
    "    config.transformer.dropout_rate = 0.1\n",
    "    config.classifier = 'token'\n",
    "    config.representation_size = None\n",
    "    return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wdOnxwzGy0zj"
   },
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "vTNAlJm9xtvf"
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "ATTENTION_Q = \"MultiHeadDotProductAttention_1/query\"\n",
    "ATTENTION_K = \"MultiHeadDotProductAttention_1/key\"\n",
    "ATTENTION_V = \"MultiHeadDotProductAttention_1/value\"\n",
    "ATTENTION_OUT = \"MultiHeadDotProductAttention_1/out\"\n",
    "FC_0 = \"MlpBlock_3/Dense_0\"\n",
    "FC_1 = \"MlpBlock_3/Dense_1\"\n",
    "ATTENTION_NORM = \"LayerNorm_0\"\n",
    "MLP_NORM = \"LayerNorm_2\"\n",
    "\n",
    "\n",
    "def np2th(weights):\n",
    "    \"\"\"Possibly convert HWIO to OIHW.\"\"\"\n",
    "    if weights.ndim == 4:\n",
    "        weights = weights.transpose([3, 2, 0, 1])\n",
    "    return torch.from_numpy(weights)\n",
    "\n",
    "def swish(x):\n",
    "    return x * torch.sigmoid(x)\n",
    "\n",
    "ACT2FN = {\"gelu\": torch.nn.functional.gelu, \"relu\": torch.nn.functional.relu, \"swish\": swish}\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, config, vis):\n",
    "        super(Attention, self).__init__()\n",
    "        self.vis = vis\n",
    "        self.num_attention_heads = config.transformer[\"num_heads\"]\n",
    "        self.attention_head_size = int(config.hidden_size / self.num_attention_heads)\n",
    "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
    "\n",
    "        self.query = Linear(config.hidden_size, self.all_head_size)\n",
    "        self.key = Linear(config.hidden_size, self.all_head_size)\n",
    "        self.value = Linear(config.hidden_size, self.all_head_size)\n",
    "\n",
    "        self.out = Linear(config.hidden_size, config.hidden_size)\n",
    "        self.attn_dropout = Dropout(config.transformer[\"attention_dropout_rate\"])\n",
    "        self.proj_dropout = Dropout(config.transformer[\"attention_dropout_rate\"])\n",
    "\n",
    "        self.softmax = Softmax(dim=-1)\n",
    "\n",
    "    def transpose_for_scores(self, x):\n",
    "        new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size)\n",
    "        x = x.view(*new_x_shape)\n",
    "        return x.permute(0, 2, 1, 3)\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        mixed_query_layer = self.query(hidden_states)\n",
    "        mixed_key_layer = self.key(hidden_states)\n",
    "        mixed_value_layer = self.value(hidden_states)\n",
    "\n",
    "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
    "        key_layer = self.transpose_for_scores(mixed_key_layer)\n",
    "        value_layer = self.transpose_for_scores(mixed_value_layer)\n",
    "\n",
    "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
    "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
    "        attention_probs = self.softmax(attention_scores)\n",
    "        weights = attention_probs if self.vis else None\n",
    "        attention_probs = self.attn_dropout(attention_probs)\n",
    "\n",
    "        context_layer = torch.matmul(attention_probs, value_layer)\n",
    "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
    "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
    "        context_layer = context_layer.view(*new_context_layer_shape)\n",
    "        attention_output = self.out(context_layer)\n",
    "        attention_output = self.proj_dropout(attention_output)\n",
    "        return attention_output, weights\n",
    "\n",
    "\n",
    "class Mlp(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(Mlp, self).__init__()\n",
    "        self.fc1 = Linear(config.hidden_size, config.transformer[\"mlp_dim\"])\n",
    "        self.fc2 = Linear(config.transformer[\"mlp_dim\"], config.hidden_size)\n",
    "        self.act_fn = ACT2FN[\"gelu\"]\n",
    "        self.dropout = Dropout(config.transformer[\"dropout_rate\"])\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        nn.init.xavier_uniform_(self.fc2.weight)\n",
    "        nn.init.normal_(self.fc1.bias, std=1e-6)\n",
    "        nn.init.normal_(self.fc2.bias, std=1e-6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act_fn(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Embeddings(nn.Module):\n",
    "    '''\n",
    "    Construct the embeddings from patch, position embeddings\n",
    "    '''\n",
    "    def __init__(self, config, img_size, in_channels=3):\n",
    "        super(Embeddings, self).__init__()\n",
    "        img_size = _pair(img_size)\n",
    "        patch_size = _pair(config.patches[\"size\"])\n",
    "        n_patches = (img_size[0]//patch_size[0]) * (img_size[1]//patch_size[1])\n",
    "\n",
    "        self.patch_embeddings = Conv2d(in_channels=in_channels,\n",
    "                                       out_channels=config.hidden_size,\n",
    "                                       kernel_size=patch_size,\n",
    "                                       stride=patch_size)\n",
    "        self.position_embeddings = nn.Parameter(torch.zeros(1, n_patches+1, config.hidden_size))\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, config.hidden_size))\n",
    "\n",
    "        self.dropout = Dropout(config.transformer[\"dropout_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        B = x.shape[0]\n",
    "        cls_tokens = self.cls_token.expand(B, -1, -1)\n",
    "\n",
    "        x = self.patch_embeddings(x)\n",
    "        x = x.flatten(2)\n",
    "        x = x.transpose(-1, -2)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "\n",
    "        embeddings = x + self.position_embeddings\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, config, vis):\n",
    "        super(Block, self).__init__()\n",
    "        self.hidden_size = config.hidden_size\n",
    "        self.attention_norm = LayerNorm(config.hidden_size, eps=1e-6)\n",
    "        self.ffn_norm = LayerNorm(config.hidden_size, eps=1e-6)\n",
    "        self.ffn = Mlp(config)\n",
    "        self.attn = Attention(config, vis)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = x\n",
    "        x = self.attention_norm(x)\n",
    "        x, weights = self.attn(x)\n",
    "        x = x + h\n",
    "\n",
    "        h = x\n",
    "        x = self.ffn_norm(x)\n",
    "        x = self.ffn(x)\n",
    "        x = x + h\n",
    "        return x, weights\n",
    "\n",
    "    def load_from(self, weights, n_block):\n",
    "        ROOT = f\"Transformer/encoderblock_{n_block}\"\n",
    "        with torch.no_grad():\n",
    "            query_weight = np2th(weights[pjoin(ROOT, ATTENTION_Q, \"kernel\")]).view(self.hidden_size, self.hidden_size).t()\n",
    "            key_weight = np2th(weights[pjoin(ROOT, ATTENTION_K, \"kernel\")]).view(self.hidden_size, self.hidden_size).t()\n",
    "            value_weight = np2th(weights[pjoin(ROOT, ATTENTION_V, \"kernel\")]).view(self.hidden_size, self.hidden_size).t()\n",
    "            out_weight = np2th(weights[pjoin(ROOT, ATTENTION_OUT, \"kernel\")]).view(self.hidden_size, self.hidden_size).t()\n",
    "\n",
    "            query_bias = np2th(weights[pjoin(ROOT, ATTENTION_Q, \"bias\")]).view(-1)\n",
    "            key_bias = np2th(weights[pjoin(ROOT, ATTENTION_K, \"bias\")]).view(-1)\n",
    "            value_bias = np2th(weights[pjoin(ROOT, ATTENTION_V, \"bias\")]).view(-1)\n",
    "            out_bias = np2th(weights[pjoin(ROOT, ATTENTION_OUT, \"bias\")]).view(-1)\n",
    "\n",
    "            self.attn.query.weight.copy_(query_weight)\n",
    "            self.attn.key.weight.copy_(key_weight)\n",
    "            self.attn.value.weight.copy_(value_weight)\n",
    "            self.attn.out.weight.copy_(out_weight)\n",
    "            self.attn.query.bias.copy_(query_bias)\n",
    "            self.attn.key.bias.copy_(key_bias)\n",
    "            self.attn.value.bias.copy_(value_bias)\n",
    "            self.attn.out.bias.copy_(out_bias)\n",
    "\n",
    "            mlp_weight_0 = np2th(weights[pjoin(ROOT, FC_0, \"kernel\")]).t()\n",
    "            mlp_weight_1 = np2th(weights[pjoin(ROOT, FC_1, \"kernel\")]).t()\n",
    "            mlp_bias_0 = np2th(weights[pjoin(ROOT, FC_0, \"bias\")]).t()\n",
    "            mlp_bias_1 = np2th(weights[pjoin(ROOT, FC_1, \"bias\")]).t()\n",
    "\n",
    "            self.ffn.fc1.weight.copy_(mlp_weight_0)\n",
    "            self.ffn.fc2.weight.copy_(mlp_weight_1)\n",
    "            self.ffn.fc1.bias.copy_(mlp_bias_0)\n",
    "            self.ffn.fc2.bias.copy_(mlp_bias_1)\n",
    "\n",
    "            self.attention_norm.weight.copy_(np2th(weights[pjoin(ROOT, ATTENTION_NORM, \"scale\")]))\n",
    "            self.attention_norm.bias.copy_(np2th(weights[pjoin(ROOT, ATTENTION_NORM, \"bias\")]))\n",
    "            self.ffn_norm.weight.copy_(np2th(weights[pjoin(ROOT, MLP_NORM, \"scale\")]))\n",
    "            self.ffn_norm.bias.copy_(np2th(weights[pjoin(ROOT, MLP_NORM, \"bias\")]))\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, config, vis):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.vis = vis\n",
    "        self.layer = nn.ModuleList()\n",
    "        self.encoder_norm = LayerNorm(config.hidden_size, eps=1e-6)\n",
    "        for _ in range(config.transformer[\"num_layers\"]):\n",
    "            layer = Block(config, vis)\n",
    "            self.layer.append(copy.deepcopy(layer))\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        attn_weights = []\n",
    "        for layer_block in self.layer:\n",
    "            hidden_states, weights = layer_block(hidden_states)\n",
    "            if self.vis:\n",
    "                attn_weights.append(weights)\n",
    "        encoded = self.encoder_norm(hidden_states)\n",
    "        return encoded, attn_weights\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, config, img_size, vis):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.embeddings = Embeddings(config, img_size=img_size)\n",
    "        self.encoder = Encoder(config, vis)\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        embedding_output = self.embeddings(input_ids)\n",
    "        encoded, attn_weights = self.encoder(embedding_output)\n",
    "        return encoded, attn_weights\n",
    "\n",
    "\n",
    "class VisionTransformer(nn.Module):\n",
    "    def __init__(self, config, img_size=224, num_classes=21843, zero_head=False, vis=False):\n",
    "        super(VisionTransformer, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.zero_head = zero_head\n",
    "        self.classifier = config.classifier\n",
    "\n",
    "        self.transformer = Transformer(config, img_size, vis)\n",
    "        self.head = Linear(config.hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x, labels=None):\n",
    "        x, attn_weights = self.transformer(x)\n",
    "        logits = self.head(x[:, 0])\n",
    "\n",
    "        if labels is not None:\n",
    "            loss_fct = CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_classes), labels.view(-1))\n",
    "            return loss\n",
    "        else:\n",
    "            return logits, attn_weights\n",
    "\n",
    "    def load_from(self, weights):\n",
    "        with torch.no_grad():\n",
    "            if self.zero_head:\n",
    "                nn.init.zeros_(self.head.weight)\n",
    "                nn.init.zeros_(self.head.bias)\n",
    "            else:\n",
    "                self.head.weight.copy_(np2th(weights[\"head/kernel\"]).t())\n",
    "                self.head.bias.copy_(np2th(weights[\"head/bias\"]).t())\n",
    "\n",
    "            self.transformer.embeddings.patch_embeddings.weight.copy_(np2th(weights[\"embedding/kernel\"]))\n",
    "            self.transformer.embeddings.patch_embeddings.bias.copy_(np2th(weights[\"embedding/bias\"]))\n",
    "            self.transformer.embeddings.cls_token.copy_(np2th(weights[\"cls\"]))\n",
    "            self.transformer.encoder.encoder_norm.weight.copy_(np2th(weights[\"Transformer/encoder_norm/scale\"]))\n",
    "            self.transformer.encoder.encoder_norm.bias.copy_(np2th(weights[\"Transformer/encoder_norm/bias\"]))\n",
    "\n",
    "            posemb = np2th(weights[\"Transformer/posembed_input/pos_embedding\"])\n",
    "            posemb_new = self.transformer.embeddings.position_embeddings\n",
    "            if posemb.size() == posemb_new.size():\n",
    "                self.transformer.embeddings.position_embeddings.copy_(posemb)\n",
    "            else:\n",
    "                logger.info(\"load_pretrained: resized variant: %s to %s\" % (posemb.size(), posemb_new.size()))\n",
    "                ntok_new = posemb_new.size(1)\n",
    "\n",
    "                if self.classifier == \"token\":\n",
    "                    posemb_tok, posemb_grid = posemb[:, :1], posemb[0, 1:]\n",
    "                    ntok_new -= 1\n",
    "                else:\n",
    "                    posemb_tok, posemb_grid = posemb[:, :0], posemb[0]\n",
    "\n",
    "                gs_old = int(np.sqrt(len(posemb_grid)))\n",
    "                gs_new = int(np.sqrt(ntok_new))\n",
    "                print('load_pretrained: grid-size from %s to %s' % (gs_old, gs_new))\n",
    "                posemb_grid = posemb_grid.reshape(gs_old, gs_old, -1)\n",
    "\n",
    "                zoom = (gs_new / gs_old, gs_new / gs_old, 1)\n",
    "                posemb_grid = ndimage.zoom(posemb_grid, zoom, order=1)\n",
    "                posemb_grid = posemb_grid.reshape(1, gs_new * gs_new, -1)\n",
    "                posemb = np.concatenate([posemb_tok, posemb_grid], axis=1)\n",
    "                self.transformer.embeddings.position_embeddings.copy_(np2th(posemb))\n",
    "\n",
    "            for bname, block in self.transformer.encoder.named_children():\n",
    "                for uname, unit in block.named_children():\n",
    "                    unit.load_from(weights, n_block=uname)\n",
    "\n",
    "\n",
    "CONFIGS = {\n",
    "    'ViT-B_16': get_b16_config(),\n",
    "    'ViT-B_32': get_b32_config(),\n",
    "    'ViT-L_16': get_l16_config(),\n",
    "    'ViT-L_32': get_l32_config(),\n",
    "    'ViT-H_14': get_h14_config(),\n",
    "    'testing': get_testing(),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B5CT23so4BmQ"
   },
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5h6Fgga44BFf",
    "outputId": "4c56d982-6949-477c-a7ae-3fe35eea4cd3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (transformer): Transformer(\n",
       "    (embeddings): Embeddings(\n",
       "      (patch_embeddings): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x Block(\n",
       "          (attention_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (ffn_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (ffn): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (attn): Attention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (proj_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (encoder_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (head): Linear(in_features=768, out_features=21843, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = CONFIGS[\"ViT-B_16\"]\n",
    "model = VisionTransformer(config, img_size=224, num_classes=21843, zero_head=False, vis=True)\n",
    "model.load_from(np.load(\"ViT-B_16.npz\"))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u33c2WQgN4yy"
   },
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "kBIivXPb3Jwc"
   },
   "outputs": [],
   "source": [
    "def get_world_size():\n",
    "    if not dist.is_available():\n",
    "        return 1\n",
    "    if not dist.is_initialized():\n",
    "        return 1\n",
    "    return dist.get_world_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K7tIVUfrOaFP"
   },
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "H0EQFpcJN6_o"
   },
   "outputs": [],
   "source": [
    "def get_loader(local_rank, img_size, dataset, train_batch_size, eval_batch_size):\n",
    "    if local_rank not in [-1, 0]:\n",
    "        torch.distributed.barrier()\n",
    "\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomResizedCrop((img_size, img_size), scale=(0.05, 1.0)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "    ])\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "    ])\n",
    "\n",
    "    if dataset == \"cifar10\":\n",
    "        trainset = datasets.CIFAR10(root=\"./data\",\n",
    "                                    train=True,\n",
    "                                    download=True,\n",
    "                                    transform=transform_train)\n",
    "        testset = datasets.CIFAR10(root=\"./data\",\n",
    "                                   train=False,\n",
    "                                   download=True,\n",
    "                                   transform=transform_test) if local_rank in [-1, 0] else None\n",
    "\n",
    "    else:\n",
    "        trainset = datasets.CIFAR100(root=\"./data\",\n",
    "                                     train=True,\n",
    "                                     download=True,\n",
    "                                     transform=transform_train)\n",
    "        testset = datasets.CIFAR100(root=\"./data\",\n",
    "                                    train=False,\n",
    "                                    download=True,\n",
    "                                    transform=transform_test) if local_rank in [-1, 0] else None\n",
    "    if local_rank == 0:\n",
    "        torch.distributed.barrier()\n",
    "\n",
    "    train_sampler = RandomSampler(trainset) if local_rank == -1 else DistributedSampler(trainset)\n",
    "    test_sampler = SequentialSampler(testset)\n",
    "    train_loader = DataLoader(trainset,\n",
    "                              sampler=train_sampler,\n",
    "                              batch_size=train_batch_size,\n",
    "                              num_workers=4,\n",
    "                              pin_memory=True)\n",
    "    test_loader = DataLoader(testset,\n",
    "                             sampler=test_sampler,\n",
    "                             batch_size=eval_batch_size,\n",
    "                             num_workers=4,\n",
    "                             pin_memory=True) if testset is not None else None\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GE2Kw1F2OzMt"
   },
   "source": [
    "### Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "5bqxK0EQO0Tj"
   },
   "outputs": [],
   "source": [
    "class ConstantLRSchedule(LambdaLR):\n",
    "    \"\"\" Constant learning rate schedule.\n",
    "    \"\"\"\n",
    "    def __init__(self, optimizer, last_epoch=-1):\n",
    "        super(ConstantLRSchedule, self).__init__(optimizer, lambda _: 1.0, last_epoch=last_epoch)\n",
    "\n",
    "\n",
    "class WarmupConstantSchedule(LambdaLR):\n",
    "    \"\"\" Linear warmup and then constant.\n",
    "        Linearly increases learning rate schedule from 0 to 1 over `warmup_steps` training steps.\n",
    "        Keeps learning rate schedule equal to 1. after warmup_steps.\n",
    "    \"\"\"\n",
    "    def __init__(self, optimizer, warmup_steps, last_epoch=-1):\n",
    "        self.warmup_steps = warmup_steps\n",
    "        super(WarmupConstantSchedule, self).__init__(optimizer, self.lr_lambda, last_epoch=last_epoch)\n",
    "\n",
    "    def lr_lambda(self, step):\n",
    "        if step < self.warmup_steps:\n",
    "            return float(step) / float(max(1.0, self.warmup_steps))\n",
    "        return 1.\n",
    "\n",
    "\n",
    "class WarmupLinearSchedule(LambdaLR):\n",
    "    \"\"\" Linear warmup and then linear decay.\n",
    "        Linearly increases learning rate from 0 to 1 over `warmup_steps` training steps.\n",
    "        Linearly decreases learning rate from 1. to 0. over remaining `t_total - warmup_steps` steps.\n",
    "    \"\"\"\n",
    "    def __init__(self, optimizer, warmup_steps, t_total, last_epoch=-1):\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.t_total = t_total\n",
    "        super(WarmupLinearSchedule, self).__init__(optimizer, self.lr_lambda, last_epoch=last_epoch)\n",
    "\n",
    "    def lr_lambda(self, step):\n",
    "        if step < self.warmup_steps:\n",
    "            return float(step) / float(max(1, self.warmup_steps))\n",
    "        return max(0.0, float(self.t_total - step) / float(max(1.0, self.t_total - self.warmup_steps)))\n",
    "\n",
    "\n",
    "class WarmupCosineSchedule(LambdaLR):\n",
    "    \"\"\" Linear warmup and then cosine decay.\n",
    "        Linearly increases learning rate from 0 to 1 over `warmup_steps` training steps.\n",
    "        Decreases learning rate from 1. to 0. over remaining `t_total - warmup_steps` steps following a cosine curve.\n",
    "        If `cycles` (default=0.5) is different from default, learning rate follows cosine function after warmup.\n",
    "    \"\"\"\n",
    "    def __init__(self, optimizer, warmup_steps, t_total, cycles=.5, last_epoch=-1):\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.t_total = t_total\n",
    "        self.cycles = cycles\n",
    "        super(WarmupCosineSchedule, self).__init__(optimizer, self.lr_lambda, last_epoch=last_epoch)\n",
    "\n",
    "    def lr_lambda(self, step):\n",
    "        if step < self.warmup_steps:\n",
    "            return float(step) / float(max(1.0, self.warmup_steps))\n",
    "        # progress after warmup\n",
    "        progress = float(step - self.warmup_steps) / float(max(1, self.t_total - self.warmup_steps))\n",
    "        return max(0.0, 0.5 * (1. + math.cos(math.pi * float(self.cycles) * 2.0 * progress)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L8cG1A7cPePP"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "snPh21bjO03W"
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def simple_accuracy(preds, labels):\n",
    "    return (preds == labels).mean()\n",
    "\n",
    "\n",
    "def save_model(output_dir, name, model):\n",
    "    model_to_save = model.module if hasattr(model, 'module') else model\n",
    "    model_checkpoint = os.path.join(output_dir, \"%s_checkpoint.bin\" % name)\n",
    "    torch.save(model_to_save.state_dict(), model_checkpoint)\n",
    "    logger.info(\"Saved model checkpoint to [DIR: %s]\", output_dir)\n",
    "\n",
    "\n",
    "def setup(model_type, img_size, pretrained_dir, device, dataset):\n",
    "    # Prepare model\n",
    "    config = CONFIGS[model_type]\n",
    "\n",
    "    num_classes = 10 if dataset == \"cifar10\" else 100\n",
    "\n",
    "    model = VisionTransformer(config, img_size, zero_head=True, num_classes=num_classes)\n",
    "    model.load_from(np.load(pretrained_dir))\n",
    "    model.to(device)\n",
    "    num_params = count_parameters(model)\n",
    "\n",
    "    logger.info(\"{}\".format(config))\n",
    "    logger.info(\"Training parameters %s\", model_type, img_size, pretrained_dir, device)\n",
    "    logger.info(\"Total Parameter: \\t%2.1fM\" % num_params)\n",
    "    return model_type, img_size, pretrained_dir, device, model\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return params/1000000\n",
    "\n",
    "\n",
    "def set_seed(seed, n_gpu):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if n_gpu > 0:\n",
    "        torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(eval_batch_size, local_rank, device, model, writer, test_loader, global_step):\n",
    "    # Validation!\n",
    "    eval_losses = AverageMeter()\n",
    "\n",
    "    logger.info(\"***** Running Validation *****\")\n",
    "    logger.info(\"  Num steps = %d\", len(test_loader))\n",
    "    logger.info(\"  Batch size = %d\", eval_batch_size)\n",
    "\n",
    "    model.eval()\n",
    "    all_preds, all_label = [], []\n",
    "    epoch_iterator = tqdm(test_loader,\n",
    "                          desc=\"Validating... (loss=X.X)\",\n",
    "                          bar_format=\"{l_bar}{r_bar}\",\n",
    "                          dynamic_ncols=True,\n",
    "                          disable=local_rank not in [-1, 0])\n",
    "    loss_fct = torch.nn.CrossEntropyLoss()\n",
    "    for step, batch in enumerate(epoch_iterator):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        x, y = batch\n",
    "        with torch.no_grad():\n",
    "            logits, attn_weights = model(x)\n",
    "\n",
    "            eval_loss = loss_fct(logits, y)\n",
    "            eval_losses.update(eval_loss.item())\n",
    "\n",
    "            preds = torch.argmax(logits, dim=-1)\n",
    "\n",
    "        if len(all_preds) == 0:\n",
    "            all_preds.append(preds.detach().cpu().numpy())\n",
    "            all_label.append(y.detach().cpu().numpy())\n",
    "        else:\n",
    "            all_preds[0] = np.append(\n",
    "                all_preds[0], preds.detach().cpu().numpy(), axis=0\n",
    "            )\n",
    "            all_label[0] = np.append(\n",
    "                all_label[0], y.detach().cpu().numpy(), axis=0\n",
    "            )\n",
    "        epoch_iterator.set_description(\"Validating... (loss=%2.5f)\" % eval_losses.val)\n",
    "\n",
    "    all_preds, all_label = all_preds[0], all_label[0]\n",
    "    accuracy = simple_accuracy(all_preds, all_label)\n",
    "\n",
    "    logger.info(\"\\n\")\n",
    "    logger.info(\"Validation Results\")\n",
    "    logger.info(\"Global Steps: %d\" % global_step)\n",
    "    logger.info(\"Valid Loss: %2.5f\" % eval_losses.avg)\n",
    "    logger.info(\"Valid Accuracy: %2.5f\" % accuracy)\n",
    "\n",
    "    writer.add_scalar(\"test/accuracy\", scalar_value=accuracy, global_step=global_step)\n",
    "    writer.add_scalar(\"test/loss\", scalar_value=eval_losses.avg, global_step=global_step)\n",
    "    return accuracy, eval_losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def cutmix_data(x, y, alpha=1.0):\n",
    "    '''Returns mixed inputs, pairs of targets, and lambda'''\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "\n",
    "    y_a, y_b = y, y[index]\n",
    "    bbx1, bby1, bbx2, bby2 = rand_bbox(x.size(), lam)\n",
    "    x[:, :, bbx1:bbx2, bby1:bby2] = x[index, :, bbx1:bbx2, bby1:bby2]\n",
    "\n",
    "    return x, y_a, y_b, lam\n",
    "\n",
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = int(W * cut_rat)\n",
    "    cut_h = int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch_nums, local_rank, output_dir, name, train_batch_size, eval_batch_size, seed, n_gpu, gradient_accumulation_steps, dataset, img_size, learning_rate, weight_decay, num_steps, decay_type, warmup_steps, fp16, fp16_opt_level, device, max_grad_norm, eval_every, model):\n",
    "    \"\"\" Train the model \"\"\"\n",
    "    if local_rank in [-1, 0]:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        writer = SummaryWriter(log_dir=os.path.join(\"logs\", name))\n",
    "\n",
    "    train_batch_size = train_batch_size // gradient_accumulation_steps\n",
    "\n",
    "    # Prepare dataset\n",
    "    train_loader, test_loader = get_loader(local_rank, img_size, dataset, train_batch_size, eval_batch_size)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # Prepare optimizer and scheduler\n",
    "    optimizer = torch.optim.SGD(model.parameters(),\n",
    "                                lr=learning_rate,\n",
    "                                momentum=0.9,\n",
    "                                weight_decay=weight_decay)\n",
    "    t_total = num_steps\n",
    "    total_step = len(train_loader)\n",
    "    if decay_type == \"cosine\":\n",
    "        scheduler = WarmupCosineSchedule(optimizer, warmup_steps=warmup_steps, t_total=t_total)\n",
    "    else:\n",
    "        scheduler = WarmupLinearSchedule(optimizer, warmup_steps=warmup_steps, t_total=t_total)\n",
    "\n",
    "    # Distributed training\n",
    "    if local_rank != -1:\n",
    "        model = DDP(model, message_size=250000000, gradient_predivide_factor=get_world_size())\n",
    "\n",
    "    # Train!\n",
    "    logger.info(\"***** Running training *****\")\n",
    "    logger.info(\"  Total optimization steps = %d\", num_steps)\n",
    "    logger.info(\"  Instantaneous batch size per GPU = %d\", train_batch_size)\n",
    "    logger.info(\"  Total train batch size (w. parallel, distributed & accumulation) = %d\",\n",
    "                train_batch_size * gradient_accumulation_steps * (\n",
    "                    torch.distributed.get_world_size() if local_rank != -1 else 1))\n",
    "    logger.info(\"  Gradient Accumulation steps = %d\", gradient_accumulation_steps)\n",
    "\n",
    "    model.zero_grad()\n",
    "    set_seed(seed, n_gpu)  # Added here for reproducibility (even between python 2 and 3)\n",
    "    losses = AverageMeter()\n",
    "    global_step, best_acc = 0, 0\n",
    "    train_accs = []\n",
    "    test_accs = []\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(epoch_nums):\n",
    "        running_loss = 0\n",
    "        running_corrects = 0\n",
    "        model.train()\n",
    "        \n",
    "        for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs = Variable(inputs.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "            \n",
    "            r = np.random.rand(1)\n",
    "            if r < 0.5:\n",
    "            # generate mixed sample\n",
    "                lam = np.random.beta(1, 1)\n",
    "                rand_index = torch.randperm(inputs.size()[0]).to(device)\n",
    "                target_a = labels\n",
    "                target_b = labels[rand_index]\n",
    "                bbx1, bby1, bbx2, bby2 = rand_bbox(inputs.size(), lam)\n",
    "                inputs[:, :, bbx1:bbx2, bby1:bby2] = inputs[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "                # adjust lambda to exactly match pixel ratio\n",
    "                lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (inputs.size()[-1] * inputs.size()[-2]))\n",
    "                # compute output\n",
    "                inputs = inputs.float()\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)[0]\n",
    "                loss = criterion(outputs, target_a) * lam + criterion(outputs, target_b) * (1. - lam)\n",
    "            else:\n",
    "                # compute output\n",
    "                inputs = inputs.float()\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)[0]\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            losses.update(loss.item() * gradient_accumulation_steps)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "            scheduler.step()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "            \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_loss += loss.item()\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            if (batch_idx) % 200 == 0:\n",
    "                    print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, epoch_nums, batch_idx, total_step, losses.val))\n",
    "\n",
    "            if local_rank in [-1, 0]:\n",
    "                writer.add_scalar(\"train/loss\", scalar_value=losses.val, global_step=global_step)\n",
    "                writer.add_scalar(\"train/lr\", scalar_value=scheduler.get_lr()[0], global_step=global_step)\n",
    "#                 train_losses.append(losses.val)\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = running_corrects.double() / len(train_loader)\n",
    "        \n",
    "        train_accs.append(epoch_acc)\n",
    "        train_losses.append(epoch_loss)\n",
    "\n",
    "        if local_rank in [-1, 0]: # global_step % eval_every == 0 and \n",
    "            accuracy, val_loss = valid(eval_batch_size, local_rank, device, model, writer, test_loader, global_step)\n",
    "            test_accs.append(accuracy)\n",
    "            val_losses.append(val_loss)\n",
    "            writer.add_scalar(\"val/loss\", scalar_value=val_loss, global_step=global_step)\n",
    "            writer.add_scalar(\"val/accuracy\", scalar_value=accuracy, global_step=global_step)\n",
    "\n",
    "            if best_acc < accuracy:\n",
    "                save_model(output_dir, name, model)\n",
    "                best_acc = accuracy\n",
    "            model.train()\n",
    "            \n",
    "        losses.reset()\n",
    "\n",
    "#     if local_rank in [-1, 0]:\n",
    "#         writer.close()\n",
    "    logger.info(\"Best Accuracy: \\t%f\" % best_acc)\n",
    "    logger.info(\"End Training!\")\n",
    "    \n",
    "    return train_accs, test_accs, train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "dfYfxZgtPpWu"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Required parameters\n",
    "    epoch_nums = 20\n",
    "    name = \"cifar10_500\"                                # Name of this run. Used for monitoring\n",
    "    dataset = \"cifar100\"                                 # Which downstream task, choices=[\"cifar10\", \"cifar100\"]\n",
    "    model_type = \"ViT-B_16\"                             # Which variant to use\n",
    "    pretrained_dir = \"ViT-B_16.npz\"            # Where to search for pretrained ViT models\n",
    "    output_dir = \"output_cifar100\"                       # The output directory where checkpoints will be written\n",
    "    img_size = 224                                      # Resolution size\n",
    "    train_batch_size = 32                               # Total batch size for training\n",
    "    eval_batch_size = 32                                # Total batch size for eval\n",
    "    eval_every = 100                                    # Run prediction on validation set every so many steps (Will always run one evaluation at the end of training)\n",
    "    learning_rate = 3e-2                                # The initial learning rate for SGD\n",
    "    weight_decay = 0                                    # Weight deay if we apply some\n",
    "    num_steps = 500                                     # Total number of training epochs to perform\n",
    "    decay_type = \"cosine\"                               # How to decay the learning rate, choices=[\"cosine\", \"linear\"]\n",
    "    warmup_steps = 100                                  # Step of training to perform learning rate warmup for\n",
    "    max_grad_norm = 1.0                                 # Max gradient norm\n",
    "    local_rank = -1                                     # local_rank for distributed training on gpus\n",
    "    seed = 42                                           # random seed for initialization\n",
    "    gradient_accumulation_steps = 1                     # Number of updates steps to accumulate before performing a backward/update pass\n",
    "    fp16 = 0                                            # (action = 'store_true') Whether to use 16-bit float precision instead of 32-bit\n",
    "    fp16_opt_level = 'store_true'                       # For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3']\n",
    "    loss_scale = 0                                      # Loss scaling to improve fp16 numeric stability. Only used when fp16 set to True (0 (default value): dynamic loss scaling, Positive power of 2: static loss scaling value)\n",
    "    local_rank = -1                                     # local_rank for distributed training on gpus\n",
    "\n",
    "    device=\"cpu\"\n",
    "    n_gpu = 0\n",
    "\n",
    "    # Setup CUDA, GPU & distributed training\n",
    "    if local_rank == -1:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        n_gpu = torch.cuda.device_count()\n",
    "    else:  # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n",
    "        torch.cuda.set_device(local_rank)\n",
    "        device = torch.device(\"cuda\", local_rank)\n",
    "        torch.distributed.init_process_group(backend='nccl',\n",
    "                                             timeout=timedelta(minutes=60))\n",
    "        n_gpu = 1\n",
    "\n",
    "    # Setup logging\n",
    "    logging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s - %(message)s',\n",
    "                        datefmt='%m/%d/%Y %H:%M:%S',\n",
    "                        level=logging.INFO if local_rank in [-1, 0] else logging.WARN)\n",
    "    logger.warning(\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\" %\n",
    "                   (local_rank, device, n_gpu, bool(local_rank != -1), fp16))\n",
    "\n",
    "    # Set seed\n",
    "    set_seed(seed, n_gpu)\n",
    "\n",
    "    # Model & Tokenizer Setup\n",
    "    model_type, img_size, pretrained_dir, device, model = setup(model_type, img_size, pretrained_dir, device, dataset)\n",
    "\n",
    "    # Training\n",
    "    train_accs, test_accs, train_losses, val_losses = train(epoch_nums, local_rank, output_dir, name, train_batch_size, eval_batch_size, seed, n_gpu, gradient_accumulation_steps, dataset, img_size, learning_rate, weight_decay, num_steps, decay_type, warmup_steps, fp16, fp16_opt_level, device, max_grad_norm, eval_every, model)\n",
    "    \n",
    "    return train_accs, test_accs, train_losses, val_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nK-ZHCjlR2tp"
   },
   "source": [
    "### Running the trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "903dc034c1764747a83fec081f0dc101",
      "55d4e9ca535f4e14aab6daa655ccb8b9",
      "54db82f6d0f34318baa919af209841ac",
      "7123e5a6e2e3441c8c2cca74b2cec744",
      "15d5f58cb9454ed2adfedd53bae5b375",
      "6fb6190cb4e24f12b8e4067ebbe7808f",
      "f0661d48681c45cd8720ca1e611313cd",
      "425296f574ff49258c84934ca5013aef"
     ]
    },
    "id": "SoKUU305PsuK",
    "outputId": "b2ab35e3-5bb6-4b9d-fe8f-d172460afaba"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: 0\n",
      "INFO:__main__:classifier: token\n",
      "hidden_size: 768\n",
      "patches:\n",
      "  size: !!python/tuple\n",
      "  - 16\n",
      "  - 16\n",
      "representation_size: null\n",
      "transformer:\n",
      "  attention_dropout_rate: 0.0\n",
      "  dropout_rate: 0.1\n",
      "  mlp_dim: 3072\n",
      "  num_heads: 12\n",
      "  num_layers: 12\n",
      "\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/lib/python3.10/logging/__init__.py\", line 1100, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/root/miniconda3/lib/python3.10/logging/__init__.py\", line 943, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/root/miniconda3/lib/python3.10/logging/__init__.py\", line 678, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/root/miniconda3/lib/python3.10/logging/__init__.py\", line 368, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/root/miniconda3/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/root/miniconda3/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/root/miniconda3/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/root/miniconda3/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/root/miniconda3/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/root/miniconda3/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/root/miniconda3/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/root/miniconda3/lib/python3.10/asyncio/base_events.py\", line 1899, in _run_once\n",
      "    handle._run()\n",
      "  File \"/root/miniconda3/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/root/miniconda3/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/root/miniconda3/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/root/miniconda3/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"/root/miniconda3/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/root/miniconda3/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/root/miniconda3/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/root/miniconda3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/root/miniconda3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/root/miniconda3/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/root/miniconda3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/root/miniconda3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/root/miniconda3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_1445/2175885637.py\", line 1, in <module>\n",
      "    train_accs, test_accs, train_losses, val_losses = main()\n",
      "  File \"/tmp/ipykernel_1445/2970243325.py\", line 52, in main\n",
      "    model_type, img_size, pretrained_dir, device, model = setup(model_type, img_size, pretrained_dir, device, dataset)\n",
      "  File \"/tmp/ipykernel_1445/2218994866.py\", line 42, in setup\n",
      "    logger.info(\"Training parameters %s\", model_type, img_size, pretrained_dir, device)\n",
      "Message: 'Training parameters %s'\n",
      "Arguments: ('ViT-B_16', 224, 'ViT-B_16.npz', device(type='cuda'))\n",
      "INFO:__main__:Total Parameter: \t85.9M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:***** Running training *****\n",
      "INFO:__main__:  Total optimization steps = 500\n",
      "INFO:__main__:  Instantaneous batch size per GPU = 32\n",
      "INFO:__main__:  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "INFO:__main__:  Gradient Accumulation steps = 1\n",
      "/root/miniconda3/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "/root/miniconda3/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:261: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Step [0/1563], Loss: 4.6052\n",
      "Epoch [1/20], Step [200/1563], Loss: 2.6044\n",
      "Epoch [1/20], Step [400/1563], Loss: 1.8997\n",
      "Epoch [1/20], Step [600/1563], Loss: 3.2102\n",
      "Epoch [1/20], Step [800/1563], Loss: 1.8325\n",
      "Epoch [1/20], Step [1000/1563], Loss: 3.5932\n",
      "Epoch [1/20], Step [1200/1563], Loss: 3.3577\n",
      "Epoch [1/20], Step [1400/1563], Loss: 0.9052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:***** Running Validation *****\n",
      "INFO:__main__:  Num steps = 313\n",
      "INFO:__main__:  Batch size = 32\n",
      "Validating... (loss=0.60127): 100%|| 313/313 [00:13<00:00, 22.74it/s]\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:Validation Results\n",
      "INFO:__main__:Global Steps: 1563\n",
      "INFO:__main__:Valid Loss: 0.59390\n",
      "INFO:__main__:Valid Accuracy: 0.87730\n",
      "INFO:__main__:Saved model checkpoint to [DIR: output_cifar100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Step [0/1563], Loss: 1.9357\n",
      "Epoch [2/20], Step [200/1563], Loss: 2.9147\n",
      "Epoch [2/20], Step [400/1563], Loss: 2.8803\n",
      "Epoch [2/20], Step [600/1563], Loss: 0.9993\n",
      "Epoch [2/20], Step [800/1563], Loss: 1.4981\n",
      "Epoch [2/20], Step [1000/1563], Loss: 1.2584\n",
      "Epoch [2/20], Step [1200/1563], Loss: 0.9640\n",
      "Epoch [2/20], Step [1400/1563], Loss: 1.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:***** Running Validation *****\n",
      "INFO:__main__:  Num steps = 313\n",
      "INFO:__main__:  Batch size = 32\n",
      "Validating... (loss=0.40792): 100%|| 313/313 [00:13<00:00, 22.73it/s]\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:Validation Results\n",
      "INFO:__main__:Global Steps: 3126\n",
      "INFO:__main__:Valid Loss: 0.39298\n",
      "INFO:__main__:Valid Accuracy: 0.89410\n",
      "INFO:__main__:Saved model checkpoint to [DIR: output_cifar100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Step [0/1563], Loss: 1.5905\n",
      "Epoch [3/20], Step [200/1563], Loss: 1.1571\n",
      "Epoch [3/20], Step [400/1563], Loss: 2.1963\n",
      "Epoch [3/20], Step [600/1563], Loss: 1.3380\n",
      "Epoch [3/20], Step [800/1563], Loss: 2.4234\n",
      "Epoch [3/20], Step [1000/1563], Loss: 1.6110\n",
      "Epoch [3/20], Step [1200/1563], Loss: 2.3502\n",
      "Epoch [3/20], Step [1400/1563], Loss: 2.7285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:***** Running Validation *****\n",
      "INFO:__main__:  Num steps = 313\n",
      "INFO:__main__:  Batch size = 32\n",
      "Validating... (loss=0.37354): 100%|| 313/313 [00:13<00:00, 22.73it/s]\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:Validation Results\n",
      "INFO:__main__:Global Steps: 4689\n",
      "INFO:__main__:Valid Loss: 0.33841\n",
      "INFO:__main__:Valid Accuracy: 0.90410\n",
      "INFO:__main__:Saved model checkpoint to [DIR: output_cifar100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Step [0/1563], Loss: 1.1455\n",
      "Epoch [4/20], Step [200/1563], Loss: 1.3221\n",
      "Epoch [4/20], Step [400/1563], Loss: 0.9073\n",
      "Epoch [4/20], Step [600/1563], Loss: 0.9679\n",
      "Epoch [4/20], Step [800/1563], Loss: 0.8148\n",
      "Epoch [4/20], Step [1000/1563], Loss: 1.2354\n",
      "Epoch [4/20], Step [1200/1563], Loss: 1.4911\n",
      "Epoch [4/20], Step [1400/1563], Loss: 1.1919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:***** Running Validation *****\n",
      "INFO:__main__:  Num steps = 313\n",
      "INFO:__main__:  Batch size = 32\n",
      "Validating... (loss=0.39038): 100%|| 313/313 [00:13<00:00, 22.78it/s]\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:Validation Results\n",
      "INFO:__main__:Global Steps: 6252\n",
      "INFO:__main__:Valid Loss: 0.31388\n",
      "INFO:__main__:Valid Accuracy: 0.91050\n",
      "INFO:__main__:Saved model checkpoint to [DIR: output_cifar100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Step [0/1563], Loss: 0.8622\n",
      "Epoch [5/20], Step [200/1563], Loss: 2.4701\n",
      "Epoch [5/20], Step [400/1563], Loss: 0.8606\n",
      "Epoch [5/20], Step [600/1563], Loss: 2.9346\n",
      "Epoch [5/20], Step [800/1563], Loss: 0.8793\n",
      "Epoch [5/20], Step [1000/1563], Loss: 2.1524\n",
      "Epoch [5/20], Step [1200/1563], Loss: 2.9305\n",
      "Epoch [5/20], Step [1400/1563], Loss: 0.8819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:***** Running Validation *****\n",
      "INFO:__main__:  Num steps = 313\n",
      "INFO:__main__:  Batch size = 32\n",
      "Validating... (loss=0.37901): 100%|| 313/313 [00:13<00:00, 22.68it/s]\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:Validation Results\n",
      "INFO:__main__:Global Steps: 7815\n",
      "INFO:__main__:Valid Loss: 0.29847\n",
      "INFO:__main__:Valid Accuracy: 0.91280\n",
      "INFO:__main__:Saved model checkpoint to [DIR: output_cifar100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Step [0/1563], Loss: 2.9660\n",
      "Epoch [6/20], Step [200/1563], Loss: 0.8009\n",
      "Epoch [6/20], Step [400/1563], Loss: 2.5313\n",
      "Epoch [6/20], Step [600/1563], Loss: 0.8486\n",
      "Epoch [6/20], Step [800/1563], Loss: 1.9183\n",
      "Epoch [6/20], Step [1000/1563], Loss: 0.6645\n",
      "Epoch [6/20], Step [1200/1563], Loss: 1.5998\n",
      "Epoch [6/20], Step [1400/1563], Loss: 0.6780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:***** Running Validation *****\n",
      "INFO:__main__:  Num steps = 313\n",
      "INFO:__main__:  Batch size = 32\n",
      "Validating... (loss=0.44262): 100%|| 313/313 [00:13<00:00, 22.59it/s]\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:Validation Results\n",
      "INFO:__main__:Global Steps: 9378\n",
      "INFO:__main__:Valid Loss: 0.29233\n",
      "INFO:__main__:Valid Accuracy: 0.91310\n",
      "INFO:__main__:Saved model checkpoint to [DIR: output_cifar100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Step [0/1563], Loss: 0.7024\n",
      "Epoch [7/20], Step [200/1563], Loss: 0.5934\n",
      "Epoch [7/20], Step [400/1563], Loss: 2.8951\n",
      "Epoch [7/20], Step [600/1563], Loss: 0.4513\n",
      "Epoch [7/20], Step [800/1563], Loss: 2.7294\n",
      "Epoch [7/20], Step [1000/1563], Loss: 2.2048\n",
      "Epoch [7/20], Step [1200/1563], Loss: 1.0477\n",
      "Epoch [7/20], Step [1400/1563], Loss: 0.6031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:***** Running Validation *****\n",
      "INFO:__main__:  Num steps = 313\n",
      "INFO:__main__:  Batch size = 32\n",
      "Validating... (loss=0.24647): 100%|| 313/313 [00:13<00:00, 22.57it/s]\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:Validation Results\n",
      "INFO:__main__:Global Steps: 10941\n",
      "INFO:__main__:Valid Loss: 0.28986\n",
      "INFO:__main__:Valid Accuracy: 0.91190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Step [0/1563], Loss: 1.9317\n",
      "Epoch [8/20], Step [200/1563], Loss: 1.1317\n",
      "Epoch [8/20], Step [400/1563], Loss: 0.9844\n",
      "Epoch [8/20], Step [600/1563], Loss: 0.8078\n",
      "Epoch [8/20], Step [800/1563], Loss: 1.3108\n",
      "Epoch [8/20], Step [1000/1563], Loss: 1.0042\n",
      "Epoch [8/20], Step [1200/1563], Loss: 2.3507\n",
      "Epoch [8/20], Step [1400/1563], Loss: 0.4620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:***** Running Validation *****\n",
      "INFO:__main__:  Num steps = 313\n",
      "INFO:__main__:  Batch size = 32\n",
      "Validating... (loss=0.31495): 100%|| 313/313 [00:13<00:00, 22.59it/s]\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:Validation Results\n",
      "INFO:__main__:Global Steps: 12504\n",
      "INFO:__main__:Valid Loss: 0.28391\n",
      "INFO:__main__:Valid Accuracy: 0.91690\n",
      "INFO:__main__:Saved model checkpoint to [DIR: output_cifar100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Step [0/1563], Loss: 0.4239\n",
      "Epoch [9/20], Step [200/1563], Loss: 0.5155\n",
      "Epoch [9/20], Step [400/1563], Loss: 2.5214\n",
      "Epoch [9/20], Step [600/1563], Loss: 2.5096\n",
      "Epoch [9/20], Step [800/1563], Loss: 2.5555\n",
      "Epoch [9/20], Step [1000/1563], Loss: 1.7304\n",
      "Epoch [9/20], Step [1200/1563], Loss: 2.5452\n",
      "Epoch [9/20], Step [1400/1563], Loss: 2.6002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:***** Running Validation *****\n",
      "INFO:__main__:  Num steps = 313\n",
      "INFO:__main__:  Batch size = 32\n",
      "Validating... (loss=0.31587): 100%|| 313/313 [00:13<00:00, 22.66it/s]\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:Validation Results\n",
      "INFO:__main__:Global Steps: 14067\n",
      "INFO:__main__:Valid Loss: 0.27687\n",
      "INFO:__main__:Valid Accuracy: 0.91890\n",
      "INFO:__main__:Saved model checkpoint to [DIR: output_cifar100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Step [0/1563], Loss: 2.1163\n",
      "Epoch [10/20], Step [200/1563], Loss: 0.5300\n",
      "Epoch [10/20], Step [400/1563], Loss: 1.9671\n",
      "Epoch [10/20], Step [600/1563], Loss: 1.6118\n",
      "Epoch [10/20], Step [800/1563], Loss: 2.0909\n",
      "Epoch [10/20], Step [1000/1563], Loss: 2.4298\n",
      "Epoch [10/20], Step [1200/1563], Loss: 1.9914\n",
      "Epoch [10/20], Step [1400/1563], Loss: 0.3159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:***** Running Validation *****\n",
      "INFO:__main__:  Num steps = 313\n",
      "INFO:__main__:  Batch size = 32\n",
      "Validating... (loss=0.28527): 100%|| 313/313 [00:13<00:00, 22.57it/s]\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:Validation Results\n",
      "INFO:__main__:Global Steps: 15630\n",
      "INFO:__main__:Valid Loss: 0.27988\n",
      "INFO:__main__:Valid Accuracy: 0.91640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Step [0/1563], Loss: 0.4702\n",
      "Epoch [11/20], Step [200/1563], Loss: 0.8140\n",
      "Epoch [11/20], Step [400/1563], Loss: 0.5487\n",
      "Epoch [11/20], Step [600/1563], Loss: 2.7998\n",
      "Epoch [11/20], Step [800/1563], Loss: 2.2850\n",
      "Epoch [11/20], Step [1000/1563], Loss: 2.5562\n",
      "Epoch [11/20], Step [1200/1563], Loss: 0.5069\n",
      "Epoch [11/20], Step [1400/1563], Loss: 0.6345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:***** Running Validation *****\n",
      "INFO:__main__:  Num steps = 313\n",
      "INFO:__main__:  Batch size = 32\n",
      "Validating... (loss=0.33843): 100%|| 313/313 [00:13<00:00, 22.81it/s]\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:Validation Results\n",
      "INFO:__main__:Global Steps: 17193\n",
      "INFO:__main__:Valid Loss: 0.28940\n",
      "INFO:__main__:Valid Accuracy: 0.91350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Step [0/1563], Loss: 0.5978\n",
      "Epoch [12/20], Step [200/1563], Loss: 0.4015\n",
      "Epoch [12/20], Step [400/1563], Loss: 2.1911\n",
      "Epoch [12/20], Step [600/1563], Loss: 0.4658\n",
      "Epoch [12/20], Step [800/1563], Loss: 2.0452\n",
      "Epoch [12/20], Step [1000/1563], Loss: 1.3677\n",
      "Epoch [12/20], Step [1200/1563], Loss: 0.6563\n",
      "Epoch [12/20], Step [1400/1563], Loss: 0.5592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:***** Running Validation *****\n",
      "INFO:__main__:  Num steps = 313\n",
      "INFO:__main__:  Batch size = 32\n",
      "Validating... (loss=0.32967): 100%|| 313/313 [00:13<00:00, 22.69it/s]\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:Validation Results\n",
      "INFO:__main__:Global Steps: 18756\n",
      "INFO:__main__:Valid Loss: 0.29365\n",
      "INFO:__main__:Valid Accuracy: 0.91220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Step [0/1563], Loss: 1.9614\n",
      "Epoch [13/20], Step [200/1563], Loss: 0.7726\n",
      "Epoch [13/20], Step [400/1563], Loss: 0.4068\n",
      "Epoch [13/20], Step [600/1563], Loss: 1.9874\n",
      "Epoch [13/20], Step [800/1563], Loss: 2.4030\n",
      "Epoch [13/20], Step [1000/1563], Loss: 0.8770\n",
      "Epoch [13/20], Step [1200/1563], Loss: 0.4232\n",
      "Epoch [13/20], Step [1400/1563], Loss: 0.3112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:***** Running Validation *****\n",
      "INFO:__main__:  Num steps = 313\n",
      "INFO:__main__:  Batch size = 32\n",
      "Validating... (loss=0.30395): 100%|| 313/313 [00:13<00:00, 22.66it/s]\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:Validation Results\n",
      "INFO:__main__:Global Steps: 20319\n",
      "INFO:__main__:Valid Loss: 0.29376\n",
      "INFO:__main__:Valid Accuracy: 0.91230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], Step [0/1563], Loss: 2.8723\n",
      "Epoch [14/20], Step [200/1563], Loss: 0.5642\n",
      "Epoch [14/20], Step [400/1563], Loss: 1.1618\n",
      "Epoch [14/20], Step [600/1563], Loss: 2.3987\n",
      "Epoch [14/20], Step [800/1563], Loss: 2.3094\n",
      "Epoch [14/20], Step [1000/1563], Loss: 0.6829\n",
      "Epoch [14/20], Step [1200/1563], Loss: 1.0010\n",
      "Epoch [14/20], Step [1400/1563], Loss: 0.9856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:***** Running Validation *****\n",
      "INFO:__main__:  Num steps = 313\n",
      "INFO:__main__:  Batch size = 32\n",
      "Validating... (loss=0.29931): 100%|| 313/313 [00:13<00:00, 22.88it/s]\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:Validation Results\n",
      "INFO:__main__:Global Steps: 21882\n",
      "INFO:__main__:Valid Loss: 0.30840\n",
      "INFO:__main__:Valid Accuracy: 0.90850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20], Step [0/1563], Loss: 0.2223\n",
      "Epoch [15/20], Step [200/1563], Loss: 2.1573\n",
      "Epoch [15/20], Step [400/1563], Loss: 0.4623\n",
      "Epoch [15/20], Step [600/1563], Loss: 2.0325\n",
      "Epoch [15/20], Step [800/1563], Loss: 1.1552\n",
      "Epoch [15/20], Step [1000/1563], Loss: 0.2470\n",
      "Epoch [15/20], Step [1200/1563], Loss: 1.0895\n",
      "Epoch [15/20], Step [1400/1563], Loss: 1.1975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:***** Running Validation *****\n",
      "INFO:__main__:  Num steps = 313\n",
      "INFO:__main__:  Batch size = 32\n",
      "Validating... (loss=0.35850): 100%|| 313/313 [00:13<00:00, 22.75it/s]\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:Validation Results\n",
      "INFO:__main__:Global Steps: 23445\n",
      "INFO:__main__:Valid Loss: 0.31242\n",
      "INFO:__main__:Valid Accuracy: 0.90730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], Step [0/1563], Loss: 2.3037\n",
      "Epoch [16/20], Step [200/1563], Loss: 0.6442\n",
      "Epoch [16/20], Step [400/1563], Loss: 1.2133\n",
      "Epoch [16/20], Step [600/1563], Loss: 2.2841\n",
      "Epoch [16/20], Step [800/1563], Loss: 0.7283\n",
      "Epoch [16/20], Step [1000/1563], Loss: 1.7652\n",
      "Epoch [16/20], Step [1200/1563], Loss: 1.9311\n",
      "Epoch [16/20], Step [1400/1563], Loss: 2.1245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:***** Running Validation *****\n",
      "INFO:__main__:  Num steps = 313\n",
      "INFO:__main__:  Batch size = 32\n",
      "Validating... (loss=0.28381): 100%|| 313/313 [00:13<00:00, 22.64it/s]\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:Validation Results\n",
      "INFO:__main__:Global Steps: 25008\n",
      "INFO:__main__:Valid Loss: 0.31264\n",
      "INFO:__main__:Valid Accuracy: 0.90760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20], Step [0/1563], Loss: 1.9111\n",
      "Epoch [17/20], Step [200/1563], Loss: 1.6397\n",
      "Epoch [17/20], Step [400/1563], Loss: 1.0568\n",
      "Epoch [17/20], Step [600/1563], Loss: 0.3818\n",
      "Epoch [17/20], Step [800/1563], Loss: 2.0259\n",
      "Epoch [17/20], Step [1000/1563], Loss: 0.7992\n",
      "Epoch [17/20], Step [1200/1563], Loss: 0.2099\n",
      "Epoch [17/20], Step [1400/1563], Loss: 1.1448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:***** Running Validation *****\n",
      "INFO:__main__:  Num steps = 313\n",
      "INFO:__main__:  Batch size = 32\n",
      "Validating... (loss=0.27384): 100%|| 313/313 [00:13<00:00, 22.71it/s]\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:Validation Results\n",
      "INFO:__main__:Global Steps: 26571\n",
      "INFO:__main__:Valid Loss: 0.32333\n",
      "INFO:__main__:Valid Accuracy: 0.90590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20], Step [0/1563], Loss: 1.5802\n",
      "Epoch [18/20], Step [200/1563], Loss: 0.3480\n",
      "Epoch [18/20], Step [400/1563], Loss: 0.7941\n",
      "Epoch [18/20], Step [600/1563], Loss: 1.1082\n",
      "Epoch [18/20], Step [800/1563], Loss: 0.7336\n",
      "Epoch [18/20], Step [1000/1563], Loss: 2.2251\n",
      "Epoch [18/20], Step [1200/1563], Loss: 0.4837\n",
      "Epoch [18/20], Step [1400/1563], Loss: 0.6399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:***** Running Validation *****\n",
      "INFO:__main__:  Num steps = 313\n",
      "INFO:__main__:  Batch size = 32\n",
      "Validating... (loss=0.27757): 100%|| 313/313 [00:13<00:00, 22.79it/s]\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:Validation Results\n",
      "INFO:__main__:Global Steps: 28134\n",
      "INFO:__main__:Valid Loss: 0.32418\n",
      "INFO:__main__:Valid Accuracy: 0.90400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], Step [0/1563], Loss: 0.5659\n",
      "Epoch [19/20], Step [200/1563], Loss: 0.5772\n",
      "Epoch [19/20], Step [400/1563], Loss: 1.3224\n",
      "Epoch [19/20], Step [600/1563], Loss: 2.2131\n",
      "Epoch [19/20], Step [800/1563], Loss: 0.2994\n",
      "Epoch [19/20], Step [1000/1563], Loss: 2.3132\n",
      "Epoch [19/20], Step [1200/1563], Loss: 0.4723\n",
      "Epoch [19/20], Step [1400/1563], Loss: 2.1584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:***** Running Validation *****\n",
      "INFO:__main__:  Num steps = 313\n",
      "INFO:__main__:  Batch size = 32\n",
      "Validating... (loss=0.32977): 100%|| 313/313 [00:13<00:00, 22.74it/s]\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:Validation Results\n",
      "INFO:__main__:Global Steps: 29697\n",
      "INFO:__main__:Valid Loss: 0.30818\n",
      "INFO:__main__:Valid Accuracy: 0.91410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], Step [0/1563], Loss: 0.5649\n",
      "Epoch [20/20], Step [200/1563], Loss: 0.6303\n",
      "Epoch [20/20], Step [400/1563], Loss: 2.2187\n",
      "Epoch [20/20], Step [600/1563], Loss: 0.3702\n",
      "Epoch [20/20], Step [800/1563], Loss: 0.5116\n",
      "Epoch [20/20], Step [1000/1563], Loss: 0.5822\n",
      "Epoch [20/20], Step [1200/1563], Loss: 2.1466\n",
      "Epoch [20/20], Step [1400/1563], Loss: 0.8542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:***** Running Validation *****\n",
      "INFO:__main__:  Num steps = 313\n",
      "INFO:__main__:  Batch size = 32\n",
      "Validating... (loss=0.26761): 100%|| 313/313 [00:13<00:00, 22.60it/s]\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:Validation Results\n",
      "INFO:__main__:Global Steps: 31260\n",
      "INFO:__main__:Valid Loss: 0.32521\n",
      "INFO:__main__:Valid Accuracy: 0.90840\n",
      "INFO:__main__:Best Accuracy: \t0.918900\n",
      "INFO:__main__:End Training!\n"
     ]
    }
   ],
   "source": [
    "train_accs, test_accs, train_losses, val_losses = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acces_list = [acc.item()/100 for acc in train_accs]\n",
    "# test_acces_list = [acc.item() for acc in test_accs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "[tensor(17.2662, device='cuda:0', dtype=torch.float64), tensor(19.8784, device='cuda:0', dtype=torch.float64), tensor(20.5125, device='cuda:0', dtype=torch.float64), tensor(20.6385, device='cuda:0', dtype=torch.float64), tensor(21.0026, device='cuda:0', dtype=torch.float64), tensor(21.0032, device='cuda:0', dtype=torch.float64), tensor(21.0122, device='cuda:0', dtype=torch.float64), tensor(21.6468, device='cuda:0', dtype=torch.float64), tensor(21.6647, device='cuda:0', dtype=torch.float64), tensor(22.1132, device='cuda:0', dtype=torch.float64), tensor(22.2367, device='cuda:0', dtype=torch.float64), tensor(22.0704, device='cuda:0', dtype=torch.float64), tensor(22.1964, device='cuda:0', dtype=torch.float64), tensor(22.5022, device='cuda:0', dtype=torch.float64), tensor(22.3544, device='cuda:0', dtype=torch.float64), tensor(22.6999, device='cuda:0', dtype=torch.float64), tensor(22.5118, device='cuda:0', dtype=torch.float64), tensor(22.6155, device='cuda:0', dtype=torch.float64), tensor(22.7479, device='cuda:0', dtype=torch.float64), tensor(22.8989, device='cuda:0', dtype=torch.float64)]\n",
      "[0.8773, 0.8941, 0.9041, 0.9105, 0.9128, 0.9131, 0.9119, 0.9169, 0.9189, 0.9164, 0.9135, 0.9122, 0.9123, 0.9085, 0.9073, 0.9076, 0.9059, 0.904, 0.9141, 0.9084]\n",
      "[2.411472231168741, 1.759644181813785, 1.6228014915437936, 1.564928121574018, 1.5254502530785912, 1.5040473157083538, 1.4733813472535469, 1.4063258038992235, 1.4142513431880388, 1.348850244657397, 1.3311287128555416, 1.332877203507524, 1.3035315914998356, 1.289879474843723, 1.3183179429981926, 1.255271976907819, 1.2746741864365487, 1.2543714391645604, 1.2414401482435578, 1.2245706920288575]\n",
      "[0.593903938230996, 0.39298371868297316, 0.3384145264284679, 0.3138806900610558, 0.2984726184163802, 0.2923261762950748, 0.28986262188504297, 0.28390771722474606, 0.27687082171868593, 0.2798816750165277, 0.28939544588636856, 0.29364653147709446, 0.2937584019923648, 0.3084039607415565, 0.3124180623231985, 0.31263735907646223, 0.32333309353647616, 0.3241770499692367, 0.30818484437327603, 0.32521489174209367]\n"
     ]
    }
   ],
   "source": [
    "print(len(train_accs)) \n",
    "print(len(test_accs))\n",
    "print(len(train_losses))\n",
    "print(len(val_losses))\n",
    "print((train_accs)) \n",
    "print((test_accs))\n",
    "print((train_losses))\n",
    "print((val_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Train-Test Accuracy\")\n",
    "plt.plot(train_acces_list, label='Training acc')\n",
    "plt.plot(test_accs, label='Test acc')\n",
    "plt.xlabel('num_epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Train-Test Loss\")\n",
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(val_losses, label='Test loss')\n",
    "plt.xlabel('num_epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Pretrained_ViT_Final.ipynb",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30716,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "5f83657021d3e7f7bbdfbc3b688aa384959ec050c4f7436829bdc8dec9d50dcb"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "15d5f58cb9454ed2adfedd53bae5b375": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "425296f574ff49258c84934ca5013aef": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "54db82f6d0f34318baa919af209841ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6fb6190cb4e24f12b8e4067ebbe7808f",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_15d5f58cb9454ed2adfedd53bae5b375",
      "value": 1
     }
    },
    "55d4e9ca535f4e14aab6daa655ccb8b9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6fb6190cb4e24f12b8e4067ebbe7808f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7123e5a6e2e3441c8c2cca74b2cec744": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_425296f574ff49258c84934ca5013aef",
      "placeholder": "​",
      "style": "IPY_MODEL_f0661d48681c45cd8720ca1e611313cd",
      "value": " 169009152/? [00:20&lt;00:00, 100121030.00it/s]"
     }
    },
    "903dc034c1764747a83fec081f0dc101": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_54db82f6d0f34318baa919af209841ac",
       "IPY_MODEL_7123e5a6e2e3441c8c2cca74b2cec744"
      ],
      "layout": "IPY_MODEL_55d4e9ca535f4e14aab6daa655ccb8b9"
     }
    },
    "f0661d48681c45cd8720ca1e611313cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
